{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ecefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685ad71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.processing.processing_pipeline import ProcessingPipeline\n",
    "\n",
    "from pipelines.processing.features.spectral_indices import CalculateIndices\n",
    "from pipelines.processing.features.basic_features import BasicFeatures\n",
    "from pipelines.processing.features.temporal_features import TemporalFeatures\n",
    "\n",
    "from pipelines.processing.processing_steps.interpolation import Interpolation\n",
    "from pipelines.processing.processing_steps.data_augmentation import DataAugmentation\n",
    "from pipelines.processing.processing_steps.adjust_labels import AdjustLabels\n",
    "from pipelines.processing.processing_steps.aggregation import TimeSeriesAggregate\n",
    "from pipelines.processing.processing_steps.interpolate_nans import InterpolateNaNs\n",
    "from pipelines.processing.processing_steps.smoothing import Smooth\n",
    "\n",
    "from pipelines.processing.data_reduction.old_disturbance_pruner import (\n",
    "    OldDisturbancePruner,\n",
    ")\n",
    "from pipelines.processing.data_reduction.detect_disturbed_trees import (\n",
    "    DetectDisturbedTrees,\n",
    ")\n",
    "from pipelines.processing.data_reduction.timeseries_filter import TimeSeriesFilter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "PATH = \"../../../data/raw/splits/trainset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786cdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(PATH, parse_dates=[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = [\n",
    "    BasicFeatures(on=True),\n",
    "    TimeSeriesAggregate(on=True, freq=2, method=\"mean\"),\n",
    "    InterpolateNaNs(on=False, method=\"linear\"),\n",
    "    Interpolation(on=True),\n",
    "    CalculateIndices(on=True),\n",
    "    TemporalFeatures(on=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 150  # ids with size <150 will be augmented\n",
    "\n",
    "train_steps = [\n",
    "    TimeSeriesFilter(on=True, max_median_diff_days=23),\n",
    "    BasicFeatures(on=False),\n",
    "    OldDisturbancePruner(on=False),\n",
    "    CalculateIndices(on=False),\n",
    "    DetectDisturbedTrees(on=False),\n",
    "    AdjustLabels(on=False),\n",
    "    DataAugmentation(on=False, threshold=threshold),\n",
    "    TimeSeriesAggregate(on=False, freq=2, method=\"mean\"),\n",
    "    InterpolateNaNs(on=False, method=\"quadratic\"),\n",
    "    Smooth(on=False),\n",
    "    Interpolation(on=False),\n",
    "    CalculateIndices(on=False), # Second time because of augmentation\n",
    "    TemporalFeatures(on=False),  \n",
    "]\n",
    "\n",
    "pipeline = ProcessingPipeline(path=PATH, steps=train_steps)\n",
    "\n",
    "df_processed = pipeline.run()\n",
    "df_processed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72510254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running processing pipeline for training data...\n",
      "(2752785, 15)\n",
      "Confusion Matrix:\n",
      " [[2960   40]\n",
      " [  48  713]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3000\n",
      "           1       0.95      0.94      0.94       761\n",
      "\n",
      "    accuracy                           0.98      3761\n",
      "   macro avg       0.97      0.96      0.96      3761\n",
      "weighted avg       0.98      0.98      0.98      3761\n",
      "\n",
      "144 ids have been removed due to predicted disturbance\n",
      "Running processing pipeline for test data...\n",
      "(784534, 15)\n",
      "Running processing pipeline for val data...\n",
      "(389953, 15)\n",
      "Training model...\n",
      "Predicting on test data...\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 830  152    3    1    4    0    4]\n",
      " [  59 1541   20   19   15    4    4]\n",
      " [   0   15 1167    0    9    1    1]\n",
      " [   0   19    0  272    1    1    2]\n",
      " [  17   30   55    1  576    0    5]\n",
      " [   0    6    1    4    2   79    1]\n",
      " [   0    6    2    1    8    1  703]]\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Norway_spruce       0.92      0.84      0.87       994\n",
      "Norway_spruce_mixed       0.87      0.93      0.90      1662\n",
      "         Scots_pine       0.94      0.98      0.96      1193\n",
      "              beech       0.91      0.92      0.92       295\n",
      "          disturbed       0.94      0.84      0.89       684\n",
      "                oak       0.92      0.85      0.88        93\n",
      "               soil       0.98      0.98      0.98       721\n",
      "\n",
      "           accuracy                           0.92      5642\n",
      "          macro avg       0.92      0.90      0.91      5642\n",
      "       weighted avg       0.92      0.92      0.92      5642\n",
      "\n",
      "\n",
      "Balanced Accuracy: 0.9041\n",
      "Predicting on test data...\n",
      "\n",
      "Confusion Matrix:\n",
      "[[395  80   1   0   3   0   4]\n",
      " [ 19 770  13  10   7   2   7]\n",
      " [  0   8 596   0   3   0   1]\n",
      " [  0   4   0 138   0   0   0]\n",
      " [  5   6  20   1 304   0   3]\n",
      " [  0   6   0   3   0  44   5]\n",
      " [  0   1   0   0   5   0 358]]\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Norway_spruce       0.94      0.82      0.88       483\n",
      "Norway_spruce_mixed       0.88      0.93      0.90       828\n",
      "         Scots_pine       0.95      0.98      0.96       608\n",
      "              beech       0.91      0.97      0.94       142\n",
      "          disturbed       0.94      0.90      0.92       339\n",
      "                oak       0.96      0.76      0.85        58\n",
      "               soil       0.95      0.98      0.96       364\n",
      "\n",
      "           accuracy                           0.92      2822\n",
      "          macro avg       0.93      0.91      0.92      2822\n",
      "       weighted avg       0.92      0.92      0.92      2822\n",
      "\n",
      "\n",
      "Balanced Accuracy: 0.9055\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pathlib import Path\n",
    "\n",
    "from pipelines.preprocessing.run_preprocessing_pipeline import run_preprocessing_pipeline\n",
    "from pipelines.processing.processing_pipeline import ProcessingPipeline\n",
    "from pipelines.processing.features.spectral_indices import CalculateIndices\n",
    "from pipelines.processing.features.basic_features import BasicFeatures\n",
    "from pipelines.processing.features.temporal_features import TemporalFeatures\n",
    "from pipelines.processing.processing_steps.interpolation import Interpolation\n",
    "\n",
    "from models.baseline_model.baseline_model_utils import drop_unwanted_columns, split_into_X_y, evaluate_model\n",
    "from models.baseline_model.calculate_keyfigures import StatisticalFeatures\n",
    "from general_utils.constants import spectral_bands, indices\n",
    "\n",
    "bands_and_indices = spectral_bands + indices \n",
    "\n",
    "BASE_DIR = Path().resolve()\n",
    "SPLITS_PATH = BASE_DIR / \"../../../data/raw/splits\"\n",
    "\n",
    "PATH_TRAIN = SPLITS_PATH / \"trainset.csv\"\n",
    "PATH_TEST = SPLITS_PATH / \"testset.csv\"\n",
    "PATH_VAL = SPLITS_PATH / \"valset.csv\"\n",
    "\n",
    "# Define processing pipeline steps\n",
    "test_steps = [\n",
    "    BasicFeatures(on=True),\n",
    "    TimeSeriesAggregate(on=False, freq=2, method=\"mean\"), \n",
    "    InterpolateNaNs(on=False, method=\"linear\"), \n",
    "    Interpolation(on=False),  \n",
    "    CalculateIndices(on=True),\n",
    "    TemporalFeatures(on=False),\n",
    "]\n",
    "\n",
    "\n",
    "threshold = 150\n",
    "train_steps = [\n",
    "    TimeSeriesFilter(on=True, max_median_diff_days=25),\n",
    "    BasicFeatures(on=True),\n",
    "    OldDisturbancePruner(on=False),\n",
    "    CalculateIndices(on=True),\n",
    "    DetectDisturbedTrees(on=True),\n",
    "    AdjustLabels(on=False),\n",
    "    DataAugmentation(on=False, threshold=threshold),\n",
    "    TimeSeriesAggregate(on=False, freq=2, method=\"mean\"),\n",
    "    InterpolateNaNs(on=False, method=\"quadratic\"),\n",
    "    Smooth(on=False),\n",
    "    Interpolation(on=False),\n",
    "    CalculateIndices(on=True), # Second time because of augmentation\n",
    "    TemporalFeatures(on=False),  \n",
    "]\n",
    "\n",
    "\n",
    "print(\"Running processing pipeline for training data...\")\n",
    "pipeline_train = ProcessingPipeline(path=PATH_TRAIN, steps=train_steps)\n",
    "df_train = pipeline_train.run()\n",
    "\n",
    "print(\"Running processing pipeline for test data...\")\n",
    "pipeline_test = ProcessingPipeline(path=PATH_TEST, steps=test_steps)\n",
    "df_test = pipeline_test.run()\n",
    "\n",
    "print(\"Running processing pipeline for val data...\")\n",
    "pipeline_test = ProcessingPipeline(path=PATH_VAL, steps=test_steps)\n",
    "df_val = pipeline_test.run()\n",
    "\n",
    "\n",
    "df_train = drop_unwanted_columns(df_train)\n",
    "df_test = drop_unwanted_columns(df_test)\n",
    "df_val = drop_unwanted_columns(df_val)\n",
    "\n",
    "sf = StatisticalFeatures()\n",
    "df_train = sf.calculate_keyfigures_per_id(df_train, bands_and_indices)\n",
    "df_test = sf.calculate_keyfigures_per_id(df_test, bands_and_indices)\n",
    "df_val = sf.calculate_keyfigures_per_id(df_val, bands_and_indices)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df_train[\"species_encoded\"] = le.fit_transform(df_train[\"species\"])\n",
    "\n",
    "X_train, y_train, X_test = split_into_X_y(df_train, df_test)\n",
    "\n",
    "# Train model\n",
    "xgb_baseline_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=len(le.classes_),\n",
    ")\n",
    "\n",
    "print(\"Training model...\")\n",
    "xgb_baseline_model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(xgb_baseline_model, X_test, df_test, le)\n",
    "\n",
    "df_val[\"species_encoded\"] = le.transform(df_val[\"species\"])\n",
    "_, _, X_val = split_into_X_y(df_train, df_val)\n",
    "evaluate_model(xgb_baseline_model, X_val, df_val, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213b9c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19584"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.id.nunique()\n",
    "#19623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca3ed4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19748"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.id.nunique()\n",
    "# 19748"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tree_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
