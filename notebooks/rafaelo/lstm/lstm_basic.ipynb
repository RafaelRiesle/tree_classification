{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6b704d",
   "metadata": {},
   "source": [
    "# LSTM-Model Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7554bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics import Accuracy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lstm_utils.sequence_model import SequenceModel\n",
    "from lstm_utils.species_dataset import SpeciesDataset\n",
    "from lstm_utils.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3488ca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc07378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_with_most_common_sample_count(df, id_column=\"id\"):\n",
    "    counts = df[id_column].value_counts()\n",
    "    most_common_count = counts.value_counts().idxmax()\n",
    "    matching_ids = counts[counts == most_common_count].index.tolist()\n",
    "    print(f\"Most common sample count: {most_common_count}\")\n",
    "    return matching_ids\n",
    "\n",
    "\n",
    "def df_to_sequences(df):\n",
    "    sequences = []\n",
    "    for id_val, group in df.groupby(\"id\"):\n",
    "        X = group[feature_columns]\n",
    "        y = group[label_column].iloc[0]  \n",
    "        sequences.append((X, y))\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d090579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common sample count: 166\n",
      "Most common sample count: 164\n",
      "Most common sample count: 154\n",
      "(46812, 15)\n",
      "(8528, 15)\n",
      "(14168, 15)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../../../data/baseline_training/trainset.csv\"\n",
    "val_path = \"../../../data/baseline_training/valset.csv\"\n",
    "test_path = \"../../../data/baseline_training/testset.csv\"\n",
    "\n",
    "\n",
    "\n",
    "loader = DataLoader()\n",
    "train_df = loader.load_transform(train_path)\n",
    "val_df = loader.load_transform(val_path)\n",
    "test_df = loader.load_transform(test_path)\n",
    "\n",
    "train_ids = set(get_ids_with_most_common_sample_count(train_df))\n",
    "val_ids   = set(get_ids_with_most_common_sample_count(val_df))\n",
    "test_ids  = set(get_ids_with_most_common_sample_count(test_df))\n",
    "\n",
    "\n",
    "\n",
    "train_df = train_df[train_df[\"id\"].isin(train_ids)].copy()\n",
    "val_df   = val_df[val_df[\"id\"].isin(val_ids)].copy()\n",
    "test_df  = test_df[test_df[\"id\"].isin(test_ids)].copy()\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96937801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        doy     b2     b3     b4     b5      b6      b7      b8     b8a  \\\n",
       " 6687   29.0   92.0  213.0  143.0  344.0   977.0  1210.0  1330.0  1420.0   \n",
       " 6688   49.0  206.0  233.0  188.0  378.0   955.0  1168.0  1392.0  1478.0   \n",
       " 6689   74.0  195.0  249.0  229.0  474.0  1097.0  1391.0  1529.0  1579.0   \n",
       " 6690   89.0  135.0  196.0  151.0  347.0   980.0  1200.0  1434.0  1505.0   \n",
       " 6691  150.0  120.0  309.0  145.0  509.0  1730.0  2080.0  2084.0  2288.0   \n",
       " ...     ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       " 6848  227.0  142.0  269.0  178.0  483.0  1630.0  2269.0  2340.0  2620.0   \n",
       " 6849  245.0  253.0  361.0  269.0  473.0  1515.0  1936.0  2015.0  2177.0   \n",
       " 6850  272.0  158.0  233.0  168.0  426.0  1555.0  1942.0  2053.0  2311.0   \n",
       " 6851  290.0  236.0  366.0  257.0  547.0  1430.0  1768.0  2155.0  2223.0   \n",
       " 6852  302.0  371.0  549.0  431.0  730.0  1451.0  1712.0  2010.0  2122.0   \n",
       " \n",
       "          b11    b12  \n",
       " 6687   531.0  306.0  \n",
       " 6688   637.0  284.0  \n",
       " 6689   864.0  460.0  \n",
       " 6690   798.0  397.0  \n",
       " 6691   965.0  393.0  \n",
       " ...      ...    ...  \n",
       " 6848  1057.0  412.0  \n",
       " 6849   945.0  408.0  \n",
       " 6850   779.0  321.0  \n",
       " 6851   794.0  371.0  \n",
       " 6852   870.0  436.0  \n",
       " \n",
       " [166 rows x 11 columns],\n",
       " 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [\n",
    "    col\n",
    "    for col in train_df.columns\n",
    "    if col not in [\"id\", \"time\", \"species\", \"disturbance_year\"]\n",
    "]\n",
    "label_column = \"species\"\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_df[label_column])             \n",
    "train_df[label_column] = le.transform(train_df[label_column])\n",
    "val_df[label_column]   = le.transform(val_df[label_column])\n",
    "test_df[label_column]  = le.transform(test_df[label_column])\n",
    "\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "\n",
    "train_sequences = df_to_sequences(train_df)\n",
    "val_sequences = df_to_sequences(val_df)\n",
    "test_sequences = df_to_sequences(test_df)\n",
    "train_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203a0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeciesDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_sequences, val_sequences, test_sequences, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.train_sequences = train_sequences\n",
    "        self.val_sequences = val_sequences\n",
    "        self.test_sequences = test_sequences\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = SpeciesDataset(self.train_sequences)\n",
    "        self.val_dataset = SpeciesDataset(self.val_sequences)\n",
    "        self.test_dataset = SpeciesDataset(self.test_sequences)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True,\n",
    "            num_workers=4, persistent_workers=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "            num_workers=4, persistent_workers=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "            num_workers=4, persistent_workers=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d79a9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeciesPredictor(pl.LightningModule):\n",
    "    def __init__(self, n_features, n_classes, lr=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SequenceModel(n_features, n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        outputs = self(sequences)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = self.train_acc(preds, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        outputs = self(sequences)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = self.val_acc(preds, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        outputs = self(sequences)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = self.test_acc(preds, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a1731e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bffe83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafaelriesle/Documents/Rafael Riesle/Studium/Semster 7/AWP2/tree_classification/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025-10-09 09:53:50.379211: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | SequenceModel      | 277 K  | train\n",
      "1 | criterion | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad71bee77ec4f86a2cb351b12917ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5feb3a0c3caf4ab0b7d3a1cc1ff6b69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f45e1bce74484b8ca7fbddab847b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605bbf1ed8b6447aa057750002afdc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_features = len(feature_columns)\n",
    "n_classes = len(set(train_df[label_column]))\n",
    "batch_size = 2\n",
    "lr = 1e-3\n",
    "max_epochs = 2\n",
    "\n",
    "# DataModule & Model\n",
    "data_module = SpeciesDataModule(\n",
    "    train_sequences, val_sequences, test_sequences, batch_size=batch_size\n",
    ")\n",
    "model = SpeciesPredictor(n_features=n_features, n_classes=n_classes, lr=lr)\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=\"gpu\" if device==\"cuda\" else \"cpu\",\n",
    "    devices=1,  \n",
    "    log_every_n_steps=10,\n",
    "    deterministic=True,\n",
    "\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393ded60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Accuracy (Train): 0.1429\n",
      "Weighted Accuracy (Validation): 0.1429\n",
      "Weighted Accuracy (Test): 0.1429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "\n",
    "def weighted_accuracy(y_true, y_pred):\n",
    "    class_counts = Counter(y_true)\n",
    "    sample_weights = [\n",
    "        1.0 / class_counts[y] for y in y_true\n",
    "    ]  \n",
    "    return accuracy_score(y_true, y_pred, sample_weight=sample_weights)\n",
    "\n",
    "\n",
    "\n",
    "def get_predictions(model, dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            seq_batch = batch[\"sequence\"].to(device)\n",
    "            label_batch = batch[\"label\"].to(device)\n",
    "            outputs = model(seq_batch)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            labels.extend(label_batch.cpu().tolist())\n",
    "    return labels, predictions\n",
    "\n",
    "\n",
    "# Train\n",
    "train_labels, train_preds = get_predictions(\n",
    "    model, data_module.train_dataloader(), device=device\n",
    ")\n",
    "train_weighted_acc = weighted_accuracy(train_labels, train_preds)\n",
    "\n",
    "# Validation\n",
    "val_labels, val_preds = get_predictions(\n",
    "    model, data_module.val_dataloader(), device=device\n",
    ")\n",
    "val_weighted_acc = weighted_accuracy(val_labels, val_preds)\n",
    "\n",
    "# Test\n",
    "test_labels, test_preds = get_predictions(\n",
    "    model, data_module.test_dataloader(), device=device\n",
    ")\n",
    "test_weighted_acc = weighted_accuracy(test_labels, test_preds)\n",
    "\n",
    "print(f\"Weighted Accuracy (Train): {train_weighted_acc:.4f}\")\n",
    "print(f\"Weighted Accuracy (Validation): {val_weighted_acc:.4f}\")\n",
    "print(f\"Weighted Accuracy (Test): {test_weighted_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
